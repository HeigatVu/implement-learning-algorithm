{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5395b31e",
   "metadata": {},
   "source": [
    "CODE WITHOUT BIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3ba3d0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7ac29843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 1., 0., 4., 2.],\n",
       "         [4., 1., 3., 0., 0., 2.],\n",
       "         [2., 1., 2., 3., 4., 1.],\n",
       "         [0., 0., 1., 3., 3., 4.],\n",
       "         [2., 3., 1., 2., 4., 0.],\n",
       "         [3., 1., 3., 2., 1., 0.]]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randint(5, (1, 6, 6), dtype=torch.float32)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "23bdfc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = nn.Conv2d(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    kernel_size=(3, 3),\n",
    "    bias=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3904b25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.3294,  0.2564, -0.1350],\n",
       "          [ 0.3111,  0.1978,  0.1526],\n",
       "          [ 0.0393,  0.1421,  0.2897]]]], requires_grad=True)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6774dafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [1., 0., 1.]]]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_kernel_weight = torch.randint(\n",
    "    high=2,\n",
    "    size=(conv_layer.weight.data.shape),\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "init_kernel_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f9ef2060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[1., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [1., 0., 1.]]]], requires_grad=True)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer.weight.data = init_kernel_weight\n",
    "conv_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3573d275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7.,  7., 11.,  6.],\n",
       "         [ 9.,  6., 10., 13.],\n",
       "         [ 7., 10., 14.,  9.],\n",
       "         [10.,  7., 10., 13.]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = conv_layer(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dbf078",
   "metadata": {},
   "source": [
    "CODE WITH BIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f22724e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.2474], requires_grad=True)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer_2 = nn.Conv2d(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    kernel_size=(3, 3),\n",
    ")\n",
    "conv_layer_2.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6b5f5cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[1., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [1., 0., 1.]]]], requires_grad=True)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer_2.weight.data = init_kernel_weight\n",
    "conv_layer_2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8d052924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1.], requires_grad=True)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init bias\n",
    "conv_layer_2.bias = nn.Parameter(torch.tensor([1], dtype=torch.float32))\n",
    "conv_layer_2.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e8564ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8.,  8., 12.,  7.],\n",
       "         [10.,  7., 11., 14.],\n",
       "         [ 8., 11., 15., 10.],\n",
       "         [11.,  8., 11., 14.]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = conv_layer_2(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce1f678",
   "metadata": {},
   "source": [
    "PADDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a5d395af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 2., 1., 2.],\n",
       "         [4., 2., 0., 4.],\n",
       "         [3., 2., 3., 1.],\n",
       "         [0., 3., 3., 1.]]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randint(5, (1, 4, 4), dtype=torch.float32)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ef89bb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[1., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [1., 0., 1.]]]], requires_grad=True)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer_3 = nn.Conv2d(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    kernel_size=(3, 3),\n",
    "    padding=(2, 1),\n",
    ")\n",
    "conv_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d7dff72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.],\n",
       "          [0., 1., 1.],\n",
       "          [0., 0., 1.]]]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_kernel_weight = torch.randint(\n",
    "    high=2,\n",
    "    size=conv_layer.weight.data.shape,\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "init_kernel_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7606ac41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[0., 0., 0.],\n",
       "          [0., 1., 1.],\n",
       "          [0., 0., 1.]]]], requires_grad=True)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer_3.weight.data = init_kernel_weight\n",
    "conv_layer_3.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a7f48611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1.], requires_grad=True)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init bias\n",
    "conv_layer_3.bias = nn.Parameter(torch.tensor([1], dtype=torch.float32))\n",
    "conv_layer_3.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f60bf08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3., 2., 3., 1.],\n",
       "         [9., 4., 8., 3.],\n",
       "         [9., 6., 6., 5.],\n",
       "         [9., 9., 6., 2.],\n",
       "         [4., 7., 5., 2.],\n",
       "         [1., 1., 1., 1.]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = conv_layer_3(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78732f27",
   "metadata": {},
   "source": [
    "STRIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "87cd6fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 4., 1., 4., 2., 4.],\n",
       "         [2., 3., 3., 4., 2., 3.],\n",
       "         [1., 3., 4., 0., 0., 1.],\n",
       "         [3., 4., 3., 3., 1., 0.],\n",
       "         [0., 4., 2., 1., 3., 3.],\n",
       "         [3., 4., 1., 4., 4., 3.]]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randint(5, (1, 6, 6), dtype=torch.float32)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e5dde7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.0488, -0.2789, -0.0849],\n",
       "          [-0.0161, -0.2296, -0.1609],\n",
       "          [-0.2498, -0.2781, -0.2217]]]], requires_grad=True)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer_4 = nn.Conv2d(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    kernel_size=(3, 3),\n",
    "    stride=(2, 2),\n",
    ")\n",
    "conv_layer_4.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "90741017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[1., 0., 1.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]]], requires_grad=True)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_kernel_weight = torch.randint(\n",
    "    high=2,\n",
    "    size=conv_layer.weight.data.shape,\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "init_kernel_weight\n",
    "conv_layer_4.weight.data = init_kernel_weight\n",
    "conv_layer_4.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3c0bbdb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1.], requires_grad=True)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init bias\n",
    "conv_layer_4.bias = nn.Parameter(torch.tensor([1], dtype=torch.float32))\n",
    "conv_layer_4.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e1f8036c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3., 4.],\n",
       "         [6., 5.]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = conv_layer_4(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63473850",
   "metadata": {},
   "source": [
    "POOLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bdf014aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 3., 3., 3., 0., 2.],\n",
       "         [3., 1., 1., 0., 0., 0.],\n",
       "         [4., 3., 1., 0., 3., 4.],\n",
       "         [0., 1., 2., 3., 4., 2.],\n",
       "         [3., 4., 4., 4., 2., 3.],\n",
       "         [4., 4., 2., 1., 3., 1.]]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randint(5, (1, 6, 6), dtype=torch.float32)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1172dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pool_layer = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3a3f7597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3., 3., 2.],\n",
       "         [4., 3., 4.],\n",
       "         [4., 4., 3.]]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = max_pool_layer(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1df2621",
   "metadata": {},
   "source": [
    "FLATTEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6bc38203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 4.],\n",
       "         [1., 1.],\n",
       "         [1., 0.]]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randint(5, (1, 3, 2), dtype=torch.float32)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b69a0b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 4., 1., 1., 1., 0.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_layer = nn.Flatten()\n",
    "output = flatten_layer(input)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aio-hw2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
